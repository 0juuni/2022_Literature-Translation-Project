{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**라이브러리**"],"metadata":{"id":"ILH6PkFwFQN8"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"nD5xxFSVERyj","executionInfo":{"status":"ok","timestamp":1664453137657,"user_tz":-540,"elapsed":298,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","#정규표현식 모듈\n","import re\n","import random\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["**데이터 준비(문장 => 단어 분할 => 벡터화)**"],"metadata":{"id":"B8uq6qJyF8qC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agvoqP1PPLoc","executionInfo":{"status":"ok","timestamp":1664453140355,"user_tz":-540,"elapsed":2222,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}},"outputId":"ebeb95a2-316b-412a-dac0-a1ca6b9dba1c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 0\n","MAX_LENGTH = 20\n","\n","#딕셔너리 구성\n","class Lang:\n","  def __init__ (self):    #단어의 인덱스 저장할 컨테이너 초기화\n","    self.word2index = {}\n","    self.word2count = {}\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"} #여기서는 SOS를 문장시작, EOS를 문장끝으로\n","    self.n_words = 2 #SOS와 EOS에 대한 카운트\n","\n","  def addSentence(self, sentence): #문장을 단어 단위로 분리한 후 컨테이너에 추가\n","    for word in sentence.split(''):\n","      self.addWord(word)\n","\n","  def addWord(self, word): #컨테이너에 단어가 없으면 추가되고, 있으면 카운트가 업데이트\n","    if word not in self.word2index:\n","      self.word2index[word] = self.n_words\n","      self.word2count[word] = 1\n","      self.index2word[self.n_words] = word\n","      self.n_words += 1\n","    else:\n","      self.word2count[word] += 1"],"metadata":{"id":"ZoLoDWgxFKaD","executionInfo":{"status":"ok","timestamp":1664453140356,"user_tz":-540,"elapsed":25,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**데이터 정규화(pandas로 불러와 정규화)**"],"metadata":{"id":"QWtVkh9cILF0"}},{"cell_type":"code","source":["def normalizeString(df, lang):\n","  sentence = df[lang].str.lower() #소문자로 전환\n","  sentence = sentence.str.replace('[ㅣ가-힣?.!,]+','') #괄호 안 제외하고 모두 공백으로 바꿈\n","  sentence = sentence.str.normalize('NFD') #NFD => 유니코드 정규화 방식\n","  sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8') #유니코드를 아스키코드로 전환\n","  return sentence\n","\n","def read_sentence(df, lang1, lang2):\n","  sentence1 = normalizeString(df, lang1) #데이터셋의 첫번째 열(고전문학본)\n","  sentence2 = normalizeString(df, lang2) #데이터셋의 두번째 열(해석본)\n","  return sentence1, sentence2\n","\n","#데이터셋 불러오기\n","def read_flie(loc, lang1, lang2):\n","  df = pd.read_csv(loc, delimiter='|', header=None, names=[lang1, lang2])\n","  return df\n","\n","def process_data(lang1, lang2):\n","  df = read_flie('/content/drive/MyDrive/관동별곡.txt'% (lang1,lang2), lang1, lang2)\n","  sentence1, sentence2 = read_sentence(df, lang1, lang2)\n","\n","#딕셔너리에 저장\n","  input_lang = Lang()\n","  output_lang = Lang()\n","  pairs = []\n","  for i in range(len(df)):\n","    if len(sentence1[i].split('')) < MAX_LENGTH and len(sentence2[i].split('')) < MAX_LENGTH:\n","      full = [sentence1[i], sentence2[i]] #첫 번째열과 두 번째 열을 합해서 저장\n","      input_lang.addSentence(sentence1[i]) #입력으로 고전문학 언어 사용\n","      output_lang.addSentence(sentence2[i]) #출력으로 해석본 언어 사용\n","      pairs.append(full) #pairs는 입력과 출력이 합쳐진 것 사용\n","    \n","    return input_lang, output_lang, pairs"],"metadata":{"id":"HRc9gSItIKWp","executionInfo":{"status":"ok","timestamp":1664453140356,"user_tz":-540,"elapsed":24,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**텐서로 변환(paris 쌍을 텐서로 변환) => pytorch는 텐서 유형의 데이터만 인식!**"],"metadata":{"id":"SKkn-kRaO2pE"}},{"cell_type":"code","source":["def indexesFromSentence(lang, sentence): #문장을 단어로 분리하고 인덱스를 반환\n","  return [lang.word2index[word] for word in sentence.split('')] \n","\n","def tensorFromSentence(lang, sentence): #딕셔너리에서 단어에 대한 인덱스를 가져오고, 문장 끝에 토큰 추가- SOS, EOS\n","  indexes = indexesFromSentence(lang, sentence)\n","  indexes.append(EOS_token)\n","  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n","\n","def tensorsFromPair(input_lang, output_lang, pair): #입력과 출력 문장을 텐서로 변환하여 반환\n","  input_tensor = tensorFromSentence(input_lang, pair[0])\n","  target_tensor = tensorFromSentence(output_lang, pair[1])\n","  return(input_tensor, target_tensor)"],"metadata":{"id":"Q2l-H1_NPFKa","executionInfo":{"status":"ok","timestamp":1664453140357,"user_tz":-540,"elapsed":25,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**인코더 네트워크(인코더 : 입력 문장을 단어별로 순서대로 인코딩을 하게 되며, 문장의 끝을 표시하는 토큰이 붙는다.**![images.png](data:image/png;base64,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)\n","\n","![images (1).png](data:image/png;base64,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)"],"metadata":{"id":"EeweRemMbsaq"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, input_dim, hidden_dim,embbed_dim, num_layers):\n","    super(Encoder, self).__init__()\n","    self.input_dim = input_dim #인코더에서 사용할 입력층\n","    self.embbed_dim = embbed_dim #인코더에서 사용할 임베딩 계층\n","    self.hidden_dim = hidden_dim #인코더에서 사용할 은닉층(이전 은닉층)\n","    self.num_layers = num_layers #인코더에서 사용할 RRU의 계층 개수\n","    self.embedding = nn.Embedding(input_dim, self.embbed_dim) #임베딩 계층 초기화\n","    self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers) #임베딩 차원, 은닉층 차원, GRU의 계층 개수를 이용하여 GRU 계층을 초기화\n","\n","  def forward(self, src):\n","    embedded = self.embedding(src).view(1, 1, -1) #임베딩 처리\n","    outputs, hidden = self.gru(embedded)\n","    return outputs, hidden\n"],"metadata":{"id":"WFXaAbWXbqRp","executionInfo":{"status":"ok","timestamp":1664453140357,"user_tz":-540,"elapsed":24,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def AttenDecoderRNN(nn.Module):\n","  def __init__(self, input_dim, hidden_dim,embbed_dim, num_layers):"],"metadata":{"id":"rd91mRl4KrPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"fiIQ1XyDKpsD"}},{"cell_type":"markdown","source":["**디코더 네트워크(디코더 : 인코더 출력을 디코딩하여 다음 출력을 예측함.) => 여기서부터 attention이 적용된 디코더를 구현하여 다른 코드로도 작성할 수 있음 => attention을 적용하면 긴 시퀀스의 문장을 처리할 때 정확도 향상을 가져올 수 있음. => 밑 코드에서는 attention 적용 X**"],"metadata":{"id":"dyyFRsL2dtrg"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n","      super(Decoder, self).__init()\n","      \n","      self.embbed_dim = embbed_dim\n","      self.hidden_dim = hidden_dim\n","      self.output_dim = output_dim\n","      self.num_layers = num_layers\n","\n","      self.embedding = nn.Embedding(output_dim, self.embbed_dim) #임베딩 계층 초기화\n","      self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers) #GRU 계층 초기화\n","      self.out = nn.Linear(self.hidden_dim, output_dim) #선형 계층 초기화\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","      input = input.view(1, -1) #입력을 (1, 배치 크기)로 변경\n","      embedded = F.relu(self.embedding(input))\n","      output, hidden = self.gru(embedded, hidden)\n","      \n","      prediction = self.softmax(self.out(output[0])) #소프트맥스는 일정한 시퀀스의 숫자들을 0과 1 사이의 양의 수로 변환해서 클래스의 확률을 구할 때 사용한다.\n","      return prediction, hidden"],"metadata":{"id":"YoiuvEcafbdr","executionInfo":{"status":"ok","timestamp":1664453140359,"user_tz":-540,"elapsed":26,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**seq2seq 네트워크**"],"metadata":{"id":"8fmjrzuvh34m"}},{"cell_type":"markdown","source":["티처포스(teacher_force)는 seq2seq 모델에서 많이 사용되는 기법이다. 티처포스는 다음 그림과 같이 번역(예측)하려는 목표 단어를 디코더의 다음 입력으로 넣어 주는 기법이다."],"metadata":{"id":"drI5yBD4_dBF"}},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","  def __init__(self, encoder, decoder,device, MAX_LENGTH=MAX_LENGTH):\n","    super().__init__\n","\n","    self.encoder = encoder #인코더 초기화\n","    self.decoder = decoder #디코더 초기화\n","    self.device = device\n","\n","  def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n","    input_length = input_lang.size(0) #입력 문자 길이(문장의 단어 수)\n","    batch_size = output_lang.shape[1]\n","    target_length = output_lang.shape[0]\n","    vocab_size = self.decoder.output_dim\n","    outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device) #예측된 출력을 저장하기 위한 변수 초기화\n","    \n","    for i in range(input_length):\n","      encoder_output, encoder_hidden = self.encoder(input_lang[i]) #문장의 모든 단어를 인코딩!\n","    decoder_hidden = encoder_hidden.to(device) #인코더의 은닉층을 디코더의 은닉층으로 사용\n","    decoder_input = torch.tensor([SOS_token], device=device) #첫 번째 예측 단어 앞에 SOS(토큰) 추가\n","\n","    for t in range(target_length): #현재 단어에서 출력 단어를 예측!\n","      decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","      outputs[t] = decoder_output\n","      teacher_force = random.random() < teacher_forcing_ratio\n","      topv, topi = decoder_output.topk(1)\n","      input = (output_lang[t] if teacher_force else topi) #teacher_force를 활성화하면 목표 단어를 다음 입력으로 사용\n","      if(teacher_force == False and input.item() == EOS_token): #teacher_force를 활성화하지않으면 자체 예측 값을 다음 입력으로 사용\n","        break\n","    return outputs"],"metadata":{"id":"JKLsuvFRjGZt","executionInfo":{"status":"ok","timestamp":1664453140360,"user_tz":-540,"elapsed":26,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["티처보드를 사용하면 학습 초기에 안정적인 훈련이 가능하고, 기울기를 계산할 때 빠른 수렴이 가능한 장점이 있지만 네트워크가 불안해질 수 있는 단점이 있다."],"metadata":{"id":"yI5TDW9pAV3j"}},{"cell_type":"markdown","source":["**모델의 오차 계산 함수 정의**"],"metadata":{"id":"JFSTYAgs_Rxj"}},{"cell_type":"markdown","source":["여기서는 모델의 오차를 계산하는 부분만 정의하기로 한다."],"metadata":{"id":"qRLh2HTJAh0Z"}},{"cell_type":"code","source":["teacher_forcing_ratio = 0.5\n","\n","def Model(model, input_tensor, target_tensor,model_optimizer, criterion):\n","  model_optimizer.zero_grad()\n","  input_length = input_tensor.size(0)\n","  loss = 0\n","  epoch_loss = 0\n","  output = model(input_tensor, target_tensor)\n","  num_iter = output.size(0)\n","\n","  for ot in range(num_iter):\n","    loss += criterion(output[ot], target_tensor[ot]) #모델의 예측 결과와 정답(예상 값? 결과?)를 이용하여 오차를 계산\n","  loss.backward()\n","  model_optimizer.step()\n","  epoch_loss = loss.item() / num_iter\n","  return epoch_loss"],"metadata":{"id":"wCoiA033_Y_0","executionInfo":{"status":"ok","timestamp":1664453140360,"user_tz":-540,"elapsed":26,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**모델 훈련 함수 정의**"],"metadata":{"id":"oE2Qj54XBxZF"}},{"cell_type":"markdown","source":["옵티마이저 및 손실 함수 등 모델에서 사용하는 피라미터를 지정한다. 사실 위의 오차 계산 함수 밑에 이어서 써도 상관은 없지만 여기서는 하나하나 분리하여 작성"],"metadata":{"id":"AGw0DeLKB1ic"}},{"cell_type":"code","source":["def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n","  model.train()\n","  optimizer = optim.SGD(model.parameters(), lr=0.01) #옵티마이저로 SGD를 사용\n","  criterion = nn.NLLLoss()\n","  total_loss_iterations = 0\n","\n","  training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))for i in range(num_iteration)]\n","\n","  for iter in range(1, num_iteration+1):\n","    training_pair = training_pairs[iter - 1]\n","    input_tensor = training_pair[0]\n","    targer_tensor = training_pair[1]\n","    loss = Model(model, input_tensor, targer_tensor, optimizer, criterion) #Model 객체를 이용하여 오차 계산\n","    total_loss_iterations += loss\n","\n","    if iter % 5000 == 0: #5000번째마다 오차 값에 대해 출력\n","      average_loss= total_loss_iterations / 5000\n","      total_loss_iterations = 0\n","      print('%d %.4f' % (iter, average_loss))\n","  torch.save(model.state_dict(), '/content/drive/MyDrive/관동별곡/mytrainging.pt')\n","  return model\n"],"metadata":{"id":"2IGUaKwEB0OZ","executionInfo":{"status":"ok","timestamp":1664453140361,"user_tz":-540,"elapsed":26,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["**모델 평가**"],"metadata":{"id":"OHbePQvBEoFm"}},{"cell_type":"code","source":["def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n","  with torch.no_grad():\n","    input_tensor = tensorFromSentence(input_lang, sentences[0]) #입력 문자를 텐서로 변환\n","    output_tensor = tensorFromSentence(output_lang, sentences[1]) #출력 문자열을 텐서로 변환\n","    decoded_words = []\n","    \n","    output = model(input_tensor, output_tensor)\n","\n","    for ot in range(output.size(0)):\n","      topv, topi = output[ot].topk(1) #각 출력에서 가장 높은 값을 찾아 인덱스를 반환\n","      \n","      if topi[0].item() == EOS_token:\n","        decoded_words.append('<EOS>') #EOS -> 끝내는 토큰을 만나면 모델의 평가를 멈춤\n","        break\n","      else:\n","        decoded_words.append(output_lang.index2word[topi[0].item()]) #예측 결과를 출력 문자열에 추가\n","  return decoded_words\n","\n","def evaluateRandomly(model, input_lang, output_lang, pairs, n=10): #훈련 데이터셋으로부터 임의의 문장을 가져와 모델 평가\n","  for i in range(n):\n","    pair = random.choice(pairs) #임의로 문장을 가져옵니다\n","    print('입력 {}'.format(pair[0]))\n","    print('번역 {}'.format(pair[1]))\n","    output_words = evaluate(model, input_lang, output_lang, pair) #모델 평가 결과는 output_words에 저장\n","    output_sentence = ''.join(output_words)\n","    print('예측 {}'.format(output_sentence))"],"metadata":{"id":"0y-S1eqiEwjF","executionInfo":{"status":"ok","timestamp":1664453140361,"user_tz":-540,"elapsed":26,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["**모델 훈련**"],"metadata":{"id":"uZbILF1wHXyW"}},{"cell_type":"code","source":["lang1 = 'ko' #고전문학\n","lang2 = 'ko2' #번역\n","input_lang, output_lang, pairs = process_data(lang1, lang2)\n","\n","randomize = random.choice(pairs)\n","print('무작위 문장 {}'.format(randomize))\n","\n","input_size = input_lang.n_words\n","output_size = output_lang.n_words\n","print('Input : {} Output : {}'.format(input_size, output_size)) #입력과 출력에 대한 단어 수 출력\n","\n","embed_size = 256\n","hidden_size = 512\n","num_layers = 1\n","num_iteration = 1000 #n번 반복하여 모델 훈련\n","\n","encoder = Encoder(input_size, hidden_size, embed_size, num_layers) #인코더에 훈련 데이터셋을 입력하고 모든 출력과 은닉 상태를 저장\n","decoder = Decoder(output_size, hidden_size, embed_size, num_layers) #디코더의 첫 번째 입력으로 <SOS> 토큰 제공, 인코더의 마지막 은닉 상태가 디코더의 첫번 째 은닉 상태로 제공\n","\n","model = Seq2Seq(encoder, decoder, device).to(device) #인코더-디코더 모델의 객체 생성\n","\n","print(encoder)\n","print(decoder)\n","\n","model = trainModel(model, input_lang, output_lang, pairs, num_iteration) #모델 학습"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"QIcEQvdqH6GX","executionInfo":{"status":"error","timestamp":1664453808055,"user_tz":-540,"elapsed":325,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}},"outputId":"532e9c89-f2bf-4c4f-fabd-9458a211138e"},"execution_count":16,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-17322d535930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlang1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ko'\u001b[0m \u001b[0;31m#고전문학\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlang2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ko2'\u001b[0m \u001b[0;31m#번역\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandomize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-decaaefb609d>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(lang1, lang2)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_flie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/관동별곡.txt'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9pqlXFkaFnDh","executionInfo":{"status":"aborted","timestamp":1664453140914,"user_tz":-540,"elapsed":15,"user":{"displayName":"딩턴이","userId":"06893929140244238996"}}},"execution_count":null,"outputs":[]}]}